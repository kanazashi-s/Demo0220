{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= \"C:/Users/USER02/Documents/Voice2Text.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "import pyaudio\n",
    "import time\n",
    "import math\n",
    "import audioop\n",
    "from six.moves import queue\n",
    "\n",
    "from google.rpc import code_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_recogRepeat = True  # 音声認識を繰り返し行う場合　Trueにする\n",
    "EXIT_WORD = u\"(音声認識を終了します|ちちんぷいぷい|さようなら)\"  # 音声認識を終了させる合言葉\n",
    "LANG_CODE = 'ja-JP'  # a BCP-47 language tag\n",
    "\n",
    "RATE = 16000  # サンプリングレート\n",
    "CHANNELS = 1  # 録音チャンネル数\n",
    "\n",
    "RECORD_SEC = 5  # 録音時間(sec)\n",
    "DEV_INDEX = 0  # デバイスを指定\n",
    "\n",
    "FRAME_SEC = 0.1  # 1フレームの時間（秒）　（0.1sec = 100ms）\n",
    "CHUNK = int(RATE * FRAME_SEC)  # 1フレーム内のサンプルデータ数\n",
    "\n",
    "SLEEP_SEC = FRAME_SEC / 4  # メインループ内でのスリープタイム（秒）\n",
    "BUF_SIZE = CHUNK * 2  # 音声のバッファ・サイズ（byte）\n",
    "\n",
    "DECIBEL_THRESHOLD = 50  # 録音開始のための閾値（dB)\n",
    "START_FRAME_LEN = 4  # 録音開始のために，何フレーム連続で閾値を超えたらいいか\n",
    "START_BUF_LEN = 5  # 録音データに加える，閾値を超える前のフレーム数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッファ用変数 #####################\n",
    "frames = []\n",
    "frames_startbuf = []\n",
    "\n",
    "flag_RecordStart = False  # 音量が規定フレーム分，閾値を超え続けたらTRUE\n",
    "flag_RecogEnd = False  # 音声認識が終わったらTrueにする\n",
    "\n",
    "recog_result = \"\"  # 音声認識結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コールバック関数 ###################\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    frames.append(in_data)\n",
    "    return (None, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_print_loop(recognize_stream):\n",
    "    global flag_RecogEnd\n",
    "    global recog_result\n",
    "    for resp in recognize_stream:\n",
    "        \n",
    "        if not resp.results:\n",
    "            continue\n",
    "\n",
    "        # 音声認識結果＆途中結果の表示 (受け取るデータの詳細は以下を参照のこと)\n",
    "        # https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.SpeechRecognitionAlternative\n",
    "        for result in resp.results:\n",
    "            if result.is_final:\n",
    "                print('is_final:'+ str(result.is_final))\n",
    "\n",
    "            for alt in result.alternatives:\n",
    "                print ('conf:' + str(alt.confidence) + \" stab:\" + str(result.stability))\n",
    "                print ('trans:' + alt.transcript)\n",
    "                recog_result = alt.transcript\n",
    "\n",
    "            # 音声認識終了（is_final: True）\n",
    "            if result.is_final:\n",
    "                flag_RecogEnd = True\n",
    "                return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_channel(host, port):\n",
    "    ssl_channel = implementations.ssl_channel_credentials(None, None, None)\n",
    "    creds = get_credentials().create_scoped([SPEECH_SCOPE])\n",
    "    auth_header = (\n",
    "        'Authorization',\n",
    "        'Bearer ' + creds.get_access_token().access_token)\n",
    "    auth_plugin = implementations.metadata_call_credentials(\n",
    "        lambda _, cb: cb([auth_header], None),\n",
    "        name='google_creds')\n",
    "\n",
    "    composite_channel = implementations.composite_channel_credentials(\n",
    "        ssl_channel, auth_plugin)\n",
    "\n",
    "    return implementations.secure_channel(host, port, composite_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_stream(channels=CHANNELS, rate=RATE, chunk=CHUNK):\n",
    "    global flag_RecogEnd\n",
    "    global LANG_CODE\n",
    "    recognition_config = cloud_speech.RecognitionConfig(\n",
    "        encoding='LINEAR16',  # raw 16-bit signed LE samples\n",
    "        sample_rate=rate,  # the rate in hertz\n",
    "        language_code=LANG_CODE,  # a BCP-47 language tag\n",
    "    )\n",
    "    streaming_config = cloud_speech.StreamingRecognitionConfig(\n",
    "        config=recognition_config,\n",
    "        interim_results=True, single_utterance=True\n",
    "    )\n",
    "\n",
    "    yield cloud_speech.StreamingRecognizeRequest(\n",
    "        streaming_config=streaming_config)\n",
    "\n",
    "    while True:\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "        if flag_RecogEnd:\n",
    "            return\n",
    "\n",
    "        # バッファにデータが溜まったら，データ送信\n",
    "        if len(frames) > 0:\n",
    "            data_1frame = frames.pop(0)\n",
    "            data_l2s = b''.join(map(str, data_1frame))\n",
    "            wf.writeframes(data_l2s)  # waveファイルに書き込み\n",
    "            yield cloud_speech.StreamingRecognizeRequest(audio_content=data_l2s)  # google ASR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneStream(object):\n",
    "    \"\"\"\n",
    "    Opens a recording stream as a generator yielding the audio chunks.\n",
    "    音声のチャンクをyieldする録音のストリームをオープンする（？？？）\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        # オーディオデータの「スレッドセーフバッファ」？？？を作成する。\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            \n",
    "            # このAPIは、現在のところモノラル音声にしか対応してない。\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            \n",
    "            # オーディオストリームを、バッファを埋めるために非同期で動かそう。\n",
    "            # これは、呼び出しているスレッドがネットワークにリクエストをしている間などであっても\n",
    "            # 入力デバイスのバッファがオーバーフロウを起こさないようにするため、必要である。\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        # ジェネレータに終了の信号を伝える。\n",
    "        # じゃないと、ストリーミング認識のメソッドが、プロセスの終了を阻害してしまう。\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            # （日訳）get()を用いて、少なくともデータが1チャンク以上あるかを確認してください。\n",
    "            # データのチャンク数がNoneを示すとき、音声ストリームは終了しています。\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            # （日訳）？？？\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "            # b''は、バイト型で文字列を送信するという記号\n",
    "            yield b''.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_stream(channels=CHANNELS, rate=RATE, chunk=CHUNK):\n",
    "    global flag_RecogEnd\n",
    "    global LANG_CODE\n",
    "    recognition_config = cloud_speech.RecognitionConfig(\n",
    "        encoding='LINEAR16',  # raw 16-bit signed LE samples\n",
    "        sample_rate=rate,  # the rate in hertz\n",
    "        language_code=LANG_CODE,  # a BCP-47 language tag\n",
    "    )\n",
    "    streaming_config = cloud_speech.StreamingRecognitionConfig(\n",
    "        config=recognition_config,\n",
    "        interim_results=True, single_utterance=True\n",
    "    )\n",
    "\n",
    "    yield cloud_speech.StreamingRecognizeRequest(\n",
    "        streaming_config=streaming_config)\n",
    "\n",
    "    while True:\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "        if flag_RecogEnd:\n",
    "            return\n",
    "\n",
    "        # バッファにデータが溜まったら，データ送信\n",
    "        if len(frames) > 0:\n",
    "            data_1frame = frames.pop(0)\n",
    "            data_l2s = b''.join(map(str, data_1frame))\n",
    "            wf.writeframes(data_l2s)  # waveファイルに書き込み\n",
    "            yield cloud_speech.StreamingRecognizeRequest(audio_content=data_l2s)  # google ASR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global frames\n",
    "    global frames_startbuf\n",
    "    print('Start Rec!')\n",
    "\n",
    "    # pyaudioオブジェクトを作成 --------------------\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    language_code = 'ja-JP'  # a BCP-47 language tag\n",
    "    \n",
    "    stream = p.open(format=p.get_format_from_width(2),\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input_device_index=DEV_INDEX,\n",
    "                    input=True,\n",
    "                    output=False,\n",
    "                    frames_per_buffer=CHUNK,\n",
    "                    stream_callback=callback)\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code)\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        # フラグ初期化 ##################################\n",
    "        flag_RecordStart = False  # 音量が規定フレーム分，閾値を超え続けたらTRUE\n",
    "        flag_RecogEnd = False  # 音声認識が終わったらTrueにする\n",
    "        # 録音開始までの処理 ##############################\n",
    "        while not flag_RecordStart:\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "            # 促音用バッファが長過ぎたら捨てる（STARTフレームより更に前のデータを保存しているバッファ）\n",
    "            if len(frames_startbuf) > START_BUF_LEN:\n",
    "                del frames_startbuf[0:len(frames_startbuf) - START_BUF_LEN]\n",
    "\n",
    "            # バッファにデータが溜まったら，録音開始するべきか判定 ---------\n",
    "            if len(frames) > START_FRAME_LEN:\n",
    "                # 1フレーム内の音量計算--------------------------------\n",
    "                for i in range(START_FRAME_LEN):\n",
    "                    # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "                    data = frames[i]\n",
    "                    rms = audioop.rms(data, 2)\n",
    "                    decibel = 20 * math.log10(rms) if rms > 0 else 0\n",
    "                    sys.stdout.write(\"\\rrms %3d decibel %f\" %(rms,decibel))\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                    # 音量が閾値より小さかったら，データを捨てループを抜ける ----\n",
    "                    if decibel < DECIBEL_THRESHOLD:\n",
    "                        frames_startbuf.append(frames[0:i + 1])\n",
    "                        del frames[0:i + 1]\n",
    "                        break\n",
    "\n",
    "                    # 全フレームの音量が閾値を超えていたら，録音開始！！ ----\n",
    "                    # 更に，framesの先頭に，先頭バッファをプラス\n",
    "                    # これをしないと「かっぱ」の「かっ」など，促音の前の音が消えてしまう\n",
    "                    if i == START_FRAME_LEN - 1:\n",
    "                        flag_RecordStart = True\n",
    "                        frames = frames_startbuf + frames\n",
    "\n",
    "        # googleサーバに接続 ############################\n",
    "        print (\"\\nconnecting ....\")\n",
    "        with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "            audio_generator = stream.generator()\n",
    "            requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                        for content in audio_generator)\n",
    "\n",
    "            responses = client.streaming_recognize(streaming_config, requests)\n",
    "        # 録音開始後の処理 ###############################\n",
    "            listen_print_loop(\n",
    "            service.StreamingRecognize(\n",
    "                request_stream(), DEADLINE_SECS))\n",
    "\n",
    "        # 音声認識 繰り返しの終了判定 #####################\n",
    "        if re.match(EXIT_WORD, recog_result):\n",
    "            print('Exiting..')\n",
    "            break\n",
    "\n",
    "        # 音声認識繰り返ししない設定 ######################\n",
    "        if not flag_recogRepeat:\n",
    "            break\n",
    "\n",
    "    # ストリームを止めて，クローズ\n",
    "    print ('Closing audio stream....')\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()  # pyaudioオブジェクトを終了\n",
    "\n",
    "    print ('End Rec!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Rec!\n",
      "rms 342 decibel 50.680522\n",
      "connecting ....\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-7a1042a9b450>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# 録音開始後の処理 ###############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             listen_print_loop(\n\u001b[1;32m---> 76\u001b[1;33m             service.StreamingRecognize(\n\u001b[0m\u001b[0;32m     77\u001b[0m                 request_stream(), DEADLINE_SECS))\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'service' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
