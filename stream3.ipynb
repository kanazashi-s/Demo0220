{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚„ã‚¯ã‚»ã®å¼·ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¤šç”¨ã•ã‚Œã¦ãŠã‚Šã€èª­ã¿ã¥ã‚‰ããªã£ã¦ã„ã¾ã™ã€‚\n",
    "- éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ç†è§£ã—ã¦ã‹ã‚‰èª­ã‚€ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= \"C:/Users/USER02/Documents/Voice2Text.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "import googleapiclient.discovery\n",
    "\n",
    "import pyaudio\n",
    "from six.moves import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸæ„Ÿæƒ…æ¨å®šç”¨ã®é–¢æ•°ã‚’å®šç¾©\n",
    "- get_native_encoding_type()ã¯ã€åˆ©ç”¨ã—ã¦ã„ã‚‹pythonã®æ–‡å­—åˆ—ã®ã‚¿ã‚¤ãƒ—ãŒutf-16ã‹utf-32ã‹ã‚’è¿”ã™\n",
    "- analyze_sentimentã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å¼•æ•°ã¨ã—ã¦æ¸¡ã™ã¨æ„Ÿæƒ…èªè­˜ã®çµæœï¼ˆè¾æ›¸å‹ï¼‰ã‚’è¿”ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_native_encoding_type():\n",
    "    \"\"\"Returns the encoding type that matches Python's native strings.\"\"\"\n",
    "    if sys.maxunicode == 65535:\n",
    "        return 'UTF16'\n",
    "    else:\n",
    "        return 'UTF32'\n",
    "    \n",
    "\n",
    "\n",
    "def analyze_sentiment(text, encoding='utf-8'):\n",
    "    body = {\n",
    "        'document': {\n",
    "            'type': 'PLAIN_TEXT',\n",
    "            'content': text,\n",
    "        },\n",
    "        'encoding_type': encoding\n",
    "    }\n",
    "\n",
    "    service = googleapiclient.discovery.build('language', 'v1')\n",
    "\n",
    "    request = service.documents().analyzeSentiment(body=body)\n",
    "    response = request.execute()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸPyaudioã‚’ç”¨ã„ã¦ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneStream(object):\n",
    "    \"\"\"\n",
    "    Opens a recording stream as a generator yielding the audio chunks.\n",
    "    éŸ³å£°ã®ãƒãƒ£ãƒ³ã‚¯ã‚’yieldã™ã‚‹éŒ²éŸ³ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã™ã‚‹ï¼ˆï¼Ÿï¼Ÿï¼Ÿï¼‰\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã®ã€Œã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãƒãƒƒãƒ•ã‚¡ã€ï¼Ÿï¼Ÿï¼Ÿã‚’ä½œæˆã™ã‚‹ã€‚\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            \n",
    "            # ã“ã®APIã¯ã€ç¾åœ¨ã®ã¨ã“ã‚ãƒ¢ãƒãƒ©ãƒ«éŸ³å£°ã«ã—ã‹å¯¾å¿œã—ã¦ãªã„ã€‚\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            \n",
    "            # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ã€ãƒãƒƒãƒ•ã‚¡ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«éåŒæœŸã§å‹•ã‹ãã†ã€‚\n",
    "            # ã“ã‚Œã¯ã€å‘¼ã³å‡ºã—ã¦ã„ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ãŒãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã—ã¦ã„ã‚‹é–“ãªã©ã§ã‚ã£ã¦ã‚‚\n",
    "            # å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã®ãƒãƒƒãƒ•ã‚¡ãŒã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ã‚¦ã‚’èµ·ã“ã•ãªã„ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã€å¿…è¦ã§ã‚ã‚‹ã€‚\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«çµ‚äº†ã®ä¿¡å·ã‚’ä¼ãˆã‚‹ã€‚\n",
    "        # ã˜ã‚ƒãªã„ã¨ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒã€ãƒ—ãƒ­ã‚»ã‚¹ã®çµ‚äº†ã‚’é˜»å®³ã—ã¦ã—ã¾ã†ã€‚\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            # ï¼ˆæ—¥è¨³ï¼‰get()ã‚’ç”¨ã„ã¦ã€å°‘ãªãã¨ã‚‚ãƒ‡ãƒ¼ã‚¿ãŒ1ãƒãƒ£ãƒ³ã‚¯ä»¥ä¸Šã‚ã‚‹ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "            # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ£ãƒ³ã‚¯æ•°ãŒNoneã‚’ç¤ºã™ã¨ãã€éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯çµ‚äº†ã—ã¦ã„ã¾ã™ã€‚\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            # ï¼ˆæ—¥è¨³ï¼‰ï¼Ÿï¼Ÿï¼Ÿ\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "            # b''ã¯ã€ãƒã‚¤ãƒˆå‹ã§æ–‡å­—åˆ—ã‚’é€ä¿¡ã™ã‚‹ã¨ã„ã†è¨˜å·\n",
    "            yield b''.join(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ã—ã€ã‚µãƒ¼ãƒã«é€ä¿¡ã™ã‚‹å‡¦ç†ã‚’ç¹°ã‚Šè¿”ã™é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_print_loop(responses, sentiment):\n",
    "    \n",
    "    \"\"\"\n",
    "    Iterates through server responses and prints them.\n",
    "    # ã‚µãƒ¼ãƒã®å¿œç­”ã‚’ç¹°ã‚Šè¿”ã—ã¦ã€ãã‚Œã‚‰ã‚’å°åˆ·ã—ã¾ã™ã€‚\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "    æ¸¡ã•ã‚Œã‚‹å¿œç­”ã¯ã€å¿œç­”ãŒã‚ã‚‹ã¾ã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã§ã™ã€‚\n",
    "    ã‚µãƒ¼ãƒãƒ¼ã«ã‚ˆã£ã¦æä¾›ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    num_chars_printed = 0\n",
    "    \n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        \n",
    "        # 'sesults'ã®ãƒªã‚¹ãƒˆã¯ã€é€£ç¶šã—ã¦ã„ã‚‹(ãŠãã‚‰ãã€ãŸãã•ã‚“ã®è¦ç´ ãŒå«ã¾ã‚Œã‚‹ã¨ã„ã†ã“ã¨)\n",
    "        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã®å ´åˆã¯ã€æœ€åˆã®çµæœã®ã¿è€ƒæ…®ã™ã‚‹ã€‚\n",
    "        # ãªãœãªã‚‰ã€ã„ã£ãŸã‚“'is_final'ã«ãªã£ãŸã‚‰ã€æ¬¡ã®ç™ºè©±ã®å‡¦ç†ã«ç§»ã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã€‚\n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        # Display the transcription of the top alternative.\n",
    "        # ãƒˆãƒƒãƒ—ã®ä»£æ›¿æ¡ˆã‚’è¡¨ç¤ºã™ã‚‹\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        \n",
    "        # æš«å®šã®çµæœã‚’è¡¨ç¤ºã™ã‚‹ã€‚ãŸã ã—ã€è¡Œæœ«ã«ã‚­ãƒ£ãƒªãƒƒã‚¸ãƒªã‚¿ãƒ¼ãƒ³ï¼Ÿï¼Ÿï¼ŸãŒã‚ã‚‹ã®ã§\n",
    "        # å¾Œç¶šã®è¡Œã¯ã“ã‚Œã‚‰ã‚’ä¸Šæ›¸ãã—ã¾ã™ã€‚\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        \n",
    "        # ã‚‚ã—ä¸€å€‹å‰ã®çµæœãŒä»Šå›ã®ã‚‚ã®ã‚ˆã‚Šã‚‚é•·ã‹ã£ãŸã‚‰ã€æˆ‘ã€…ã¯è¿½åŠ ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’\n",
    "        # å‰å›ã®çµæœã‚’ä¸Šæ›¸ãã™ã‚‹ãŸã‚ã«è¿½åŠ ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\n",
    "        overwrite_chars = ' ' * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + '\\r')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            num_chars_printed = len(transcript)\n",
    "\n",
    "        else:\n",
    "            print_str = transcript + overwrite_chars\n",
    "            \n",
    "            if sentiment:\n",
    "                \n",
    "                mag, score = analyze_sentiment(transcript + overwrite_chars, get_native_encoding_type())['documentSentiment'].values()\n",
    "                print_str += '\\næ„Ÿæƒ…ã®æ­£è² :{} æ„Ÿæƒ…ã®å¼·ã•:{}\\n'.format(score, mag)\n",
    "                \n",
    "            yield print_str\n",
    "            \n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            \n",
    "            # è»¢è¨˜ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ã‚ºã®ã„ãšã‚Œã‹ãŒGoogleã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®1ã¤ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã¯\n",
    "            # èªè­˜ã‚’çµ‚äº†ã—ã¦ãã ã•ã„ã€‚\n",
    "            if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\n",
    "                print('Exiting..')\n",
    "                break\n",
    "\n",
    "            num_chars_printed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸãƒ¡ã‚¤ãƒ³é–¢æ•°\n",
    "- è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ[è©³ç´°](https://cloud.google.com/speech-to-text/docs/languages)ï¼‰ã¨ã€æ„Ÿæƒ…æ¨å®šã™ã‚‹ã‹å¦ã‚’å¼•æ•°ã«ã¨ã‚‹\n",
    "- ã“ã‚Œå‘¼ã³å‡ºã™ã¹ã—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(lang='ja-JP', sentiment=False):\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = lang  # a BCP-47 language tag\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code)\n",
    "    streaming_config = types.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True)\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (types.StreamingRecognizeRequest(audio_content=content)\n",
    "                    for content in audio_generator)\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "        \n",
    "        loopitr = listen_print_loop(responses, sentiment)\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # Now, put the transcription responses to use.\n",
    "                print(next(loopitr))\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nğŸŒ¸ğŸŒ¸ğŸŒ¸Interrupted!!!ğŸŒ¸ğŸŒ¸ğŸŒ¸')\n",
    "            return 0\n",
    "        except :\n",
    "            return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸå®Ÿè¡Œéƒ¨åˆ†\n",
    "- mainï¼ˆè¨€èªã‚³ãƒ¼ãƒ‰, æ„Ÿæƒ…æ¨å®šOnOffï¼‰\n",
    "- ã‚‚ã—65ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§ä¸­æ–­ã—ã¦ã—ã¾ã£ãŸå ´åˆã¯ã€ã‚‚ã†ä¸€åº¦å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«ç„¡é™ãƒ«ãƒ¼ãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    result = main('ja-JP', True)\n",
    "    if result == 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
